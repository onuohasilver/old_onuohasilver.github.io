---
layout: post
title:  "Batch Jobs"
categories: RCE
---

Running a job in batch mode is extremely useful for performing long processes in the background, while freeing the GUI interface for other tasks. Even though a particular Stata task is not performed faster in batch mode, it allows to perform several tasks in parallel.

In this post I explain the basics of running batch jobs with Stata. I also wrote a [second part](batch-processes) which deals with running multiple processes in parallel.

# What do I need?

### A do-file
First of all you need a do-file to submit. In this example we'll submit `mydofile.do`. The do-file hasn't have to have anything special (at least at first).

### A submit file
You'll need a `submit file`, which is a simple text file with instructions on how the batch process should be run. **The submit file has to be saved with a `*.submit` extension.** So, for example, I'll name mine `mybatch.submit` (again, creative).

The easiest way to get going is to copy the following text in any plain text editor and then make sure to save it with `*.submit` extension (not `*.submit.txt`!). All lines starting with a `#` are comments. Edit what you want and save the file in the same folder as your do-file.

```c
# Universe whould always be 'vanilla'. This line MUST be
#included in your submit file, exactly as shown below.
Universe = vanilla

# The path to Stata (could be R or Matlab)
Executable = /usr/local/bin/stata-mp

# Specify any arguments you want to pass to the executable.
# Here we pass arguments to make Stata run the bootstrap.do
# file. We also pass the process number, which will be used
# to append the process number to the output files.
Arguments = -q do mydofile.do

# Specify where to output any results printed by your program.
output = output/mydofile.out
# Specify where to save any errors returned by your program.
error = output/mydofile.err
# Specify where to save the log file.
Log = output/mydofile.log

# Request processors (Stata maxes out at 4) and memory (in GB)
Request_Cpus = 4
Request_Memory = 8GB

# Notifications settings
notification = Always
notify_user = your@email.com

# Enter the number of processes to request.
# This section should always come last.
Queue 1
```

### Directory structure

Both the `do-file` and the `submit file` should be placed on a directory of your choosing, which we'll call the `root directory`. It is recommended to have a dedicated folder for the outputs produced by the batch processing system inside the `root directory`. In this example I've been exceedingly creative and named that folder `/output`.

# Submitting a batch job

Now that everything is set up, the process is really easy. You'll need to start the command line and change directory to the `root directory`. For example,

````
$ cd /nfs/projects/t/tpricing
````

Once there, the process is submitted with the `condor_submit <submit file>.submit` command. For example,

````
$ condor_submit mybatch.submit
````

It will then say that the job is submitted to a cluster number.

# Checking the process

You can check at anytime how all your submitted processes are going by typing `condor_q <username>`. For example,

````
$ condor_q acarril2
````
The most important column in there is `ST`, shorthand for "Status". If it says `R`, then it is running. **If you don't see your process, then that means it has finished.** If that is the case, go to your `/output` folder and check your results in the `*.out` file.

Better than checking incessantly, make sure you add your email address to the `submit file`, so you get notified in your inbox when your job completes (or crashes)!
