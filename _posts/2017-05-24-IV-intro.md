---
layout: post
title: "How do instrumental variables work?"
---

![](http://ep60qmdjq8-flywheel.netdna-ssl.com/wp-content/uploads/2014/08/rube.png)

As Angrist and Pischke put it, "causal inference has always been the name of the game in applied econometrics", and the method of [instrumental variables](https://en.wikipedia.org/wiki/Instrumental_variable) is a core part of the 'metrics toolkit. In this post I'll cover how it resolves a fundamental issue in causal inference models, trying to be clear about the intuition behind its implementation.

<!--more-->

When we write down a model like

$$y_i = \alpha + \beta \cdot x_i + \epsilon_i \tag{1}$$

we can think of it as a convenient way of modeling $$E[y\mid x]$$, or a way of predicting $$y$$ based on $$x$$'s values. However, **in applied econometrics models are usally meant to answer a question of causality**: "by how much does a change in $$x$$ affect $$y$$?"

At the risk of oversimplifying, when estimating this model with OLS we basically assume that:

1. $$x$$ and $$\epsilon$$ cause $$y$$
2. $$y$$ and $$\epsilon$$ do not cause $$x$$ 
3. Nothing that causes $$\epsilon$$ also causes $$x$$.

A perfect (?) [randomized controlled trial](https://en.wikipedia.org/wiki/Randomized_controlled_trial) is a way of *forcing* 2 and 3 to be true: if you pick $$x$$ randomly, then it surely isn't being caused by $$y$$, $$\epsilon$$... or any other thing, for that matter. So-called [natural experiments](https://en.wikipedia.org/wiki/Natural_experiment) are cases when special circumstances arise in which 2 and 3 seem plausible, even though that usually isn't the case.


## The problem with causation and the omitted variable bias

Suppose we want to estimate the causal effect of $$x$$ on $$y$$, but we suspect that the explanatory variable and error term may be correlated:

$$\begin{matrix}y_i &=& \alpha &+& \beta x_i &+&   \epsilon_i & \\ & && & & \hspace{-1cm}\nwarrow & \hspace{-0.8cm} \nearrow \\ &  & & & & \text{corr} &   \end{matrix}$$

This correlation may arise because we forgot (or can't include/measure) an important variable ---in terms of explaining $$y$$--- that correlates with $$x$$. This produces a problem usually referred to as the **omitted variable bias**, which is a variable that is correlated with both an independent variable in the model, and with the error term. This is equivalent to saying that the omitted variable both affects the independent variable and separately affects the dependent variable, which leads to endogeneity. In this case $$\hat\beta$$ will not give us the causal effect of $$x$$ on $$y$$.

For example, consider the good ol' [Mincer equation](https://en.wikipedia.org/wiki/Mincer_earnings_function) where $$y_i$$ is wage and education is $$x_i$$, that is, we're trying to explain wages using education level:

$$ \text{wage}_i = \alpha + \beta\cdot\text{education}_i + \epsilon_i $$

It can be argued that "individual ability" is a very important factor in determining education: people with more ability in something tend to specialize/study more. So education correlates with "individual ability", which is part of the error term (because it is not included explicitely in the model).


# The instrumental variable

An instrument is a new variable $$z_i$$ which is uncorrelated with $$\epsilon_i$$, but that correlates well with $$x_i$$ and which only influences $$y_i$$ through $$x_i$$:

$$\begin{matrix}
z_i & \rightarrow & x_i & \rightarrow & y_i \newline
  &   & \uparrow & \nearrow & \newline
 & & \epsilon_i &  
\end{matrix}$$

For example, we might think of using father's education as an instrument. It could be argued that father's education is highly correlated with any person's own education, but at the same time doesn't affect any unobserved "individual ability" which may be part of the error term. This is debatable, and constitutes a first lesson on instrumental variables: *the choice of a valid instrument is always debatable.*

## How does this solve the endogeneity problem?

We can thing of the total variation of our dependant variable $$x_i$$ as having two parts: an explained and an unexplained part, that is,

$$
\underbrace{x_i}_{\text{total variation}} = \underbrace{\gamma \quad + \quad \pi \cdot z_i}_{\text{explained variation}} \quad + \underbrace{\eta_i}_{\text{unexplained variation}} \tag{2}
$$

We know that at least the explained variation of $$x_i$$ is exogenous to our main equation, because it is produced by $$z_i$$, which is (supposed to be) exogenous. Part of the unexplained variation of $$x_i$$ is "bad" for us, because it correlates with with $$\epsilon_i$$, which is our main issue.
So what we do is just dismiss the unexplained part of the variation, defining

$$\widehat{x_i}=\gamma + \pi \cdot z_i$$

and substituting it in the original equation, which means we end up with

$$y_i = \alpha + \beta \cdot \widehat{x_i} + \epsilon_i \tag{3}$$


And we're done! Because we "filtered out" the part of $$x_i$$ that was correlated with the error term, eq. $$(3)$$ can be consistently estimated. **The instrument serves the purpose of breaking the correlation between the explanatory variable and the error, thus solving the endogeneity problem.**

$$
\begin{matrix}
& &  &     &             & \widehat{x}_i \newline
& &  &     &    \nearrow         & \downarrow \newline
& z_i & \rightarrow  & x_i &  & y_i \newline
  & & &  & \nearrow & \newline
 & & & \epsilon_i &  
\end{matrix}
$$

This diagram describes the steps we took to solve the problem: by using $$z_i$$ to affect $$x_i$$, we avoid the effect of $$\epsilon_i$$ on $$x_i$$. In order to achieve this we must take a slight "detour" and use $$\widehat{x_i}$$ instead of $$x_i$$. **The cost of this detour is that our model will tend to be less precise**, that is, standard errors will tend to be larger.


## Validity of the instrument

So how can we find "good" instruments? Let's take a look at its assumptions more closely:

- The instrument must be correlated with the endogenous variable, or **inclusion restriction**.
- The instrument cannot be correlated with the error term, or **exclusion restriction**.

The inclusion restriction is ---in some sense--- easier to meet, because it can be easily tested by analyzing how closely correlated $$z_i$$ is with $$x_i$$. In terms of our example, just check the correlation between an individual's father's education and his own.

Then, then **validity of an instrument** depends largely on making a good case as to why $$z_i$$ (e.g. father's education) would not be correlated with $$\epsilon_i$$ (e.g. "individual ability"). This cannot be formally tested, because the true error remains unobserved. So usual suspects for instruments include things that can be plausibly seen as exogenous: natural disasters, policy changes, or even randomly allocated treatments (which is equivalent to creating a perfectly valid instrument).

